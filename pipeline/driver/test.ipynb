{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-10T20:24:41.378581Z",
     "start_time": "2024-03-10T20:24:38.733771Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/03/11 12:11:24 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "24/03/11 12:11:25 WARN StandaloneSchedulerBackend: Dynamic allocation enabled without spark.executor.cores explicitly set, you may get more executors allocated than expected. It's recommended to set spark.executor.cores explicitly. Please check SPARK-30299 for more details.\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "\n",
    "############################################################\n",
    "# Setup session and files\n",
    "############################################################\n",
    "\n",
    "spark_session = SparkSession \\\n",
    "    .builder \\\n",
    "    .master(\"spark://spark-master:7077\") \\\n",
    "    .appName(\"tessst\") \\\n",
    "    .config(\"spark.dynamicAllocation.enabled\", True) \\\n",
    "    .config(\"spark.dynamicAllocation.shuffleTracking.enabled\",True) \\\n",
    "    .config(\"spark.shuffle.service.enabled\", False) \\\n",
    "    .config(\"spark.driver.port\", 9999) \\\n",
    "    .config(\"spark.blockManager.port\", 10005) \\\n",
    "    .config(\"spark.dynamicAllocation.executorIdleTimeout\",\"30s\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "sc = spark_session.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eb8df9070dcbecab",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-03-10T20:24:48.029661Z"
    },
    "collapsed": false,
    "is_executing": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Row(author='raysofdarkmatter', body=\"I think it should be fixed on either UTC standard or UTC+1 year around, with the current zone offsets.\\n\\nMoving timescales add a lot of complexity to the implementation of timekeeping systems and have [dubious value]( \\n\\nI think seasonal shifting time made sense in the pre-electric past, when timekeeping was more flexible and artificial light was inefficient and often dangerous. \\n\\nNow we have machines that work easily with simple timekeeping rules, and it's more beneficial to spend a small amount on energy for lighting, and save the larger cost of engineering things to work with the complex timekeeping rules, as well as saving the irritation to humans.\\n\\nLighting has gotten much more efficient over time; we can squeeze out a lot more photons per unit of energy from a 2012 CFL or LED than a candle could in 1780, or a lightbulb could in 1950. \\n\\nThere's a lot of room for improvement in how we use lights as well; as lighting control gets more intelligent, there will be a lot of savings from not illuminating inactive spaces constantly.\\n\\ntl;dr: Shifting seasonal time is no longer worth it.\", content=\"I think it should be fixed on either UTC standard or UTC+1 year around, with the current zone offsets. \\n Moving timescales add a lot of complexity to the implementation of timekeeping systems and have [dubious value]( \\n I think seasonal shifting time made sense in the pre-electric past, when timekeeping was more flexible and artificial light was inefficient and often dangerous. \\n Now we have machines that work easily with simple timekeeping rules, and it's more beneficial to spend a small amount on energy for lighting, and save the larger cost of engineering things to work with the complex timekeeping rules, as well as saving the irritation to humans. \\n Lighting has gotten much more efficient over time; we can squeeze out a lot more photons per unit of energy from a 2012 CFL or LED than a candle could in 1780, or a lightbulb could in 1950. \\n There's a lot of room for improvement in how we use lights as well; as lighting control gets more intelligent, there will be a lot of savings from not illuminating inactive spaces constantly.\", content_len=178, id='c69al3r', normalizedBody=\"I think it should be fixed on either UTC standard or UTC+1 year around, with the current zone offsets. \\n Moving timescales add a lot of complexity to the implementation of timekeeping systems and have [dubious value]( \\n I think seasonal shifting time made sense in the pre-electric past, when timekeeping was more flexible and artificial light was inefficient and often dangerous. \\n Now we have machines that work easily with simple timekeeping rules, and it's more beneficial to spend a small amount on energy for lighting, and save the larger cost of engineering things to work with the complex timekeeping rules, as well as saving the irritation to humans. \\n Lighting has gotten much more efficient over time; we can squeeze out a lot more photons per unit of energy from a 2012 CFL or LED than a candle could in 1780, or a lightbulb could in 1950. \\n There's a lot of room for improvement in how we use lights as well; as lighting control gets more intelligent, there will be a lot of savings from not illuminating inactive spaces constantly. \\n tl;dr: Shifting seasonal time is no longer worth it. \\n\", subreddit='math', subreddit_id='t5_2qh0n', summary='Shifting seasonal time is no longer worth it.', summary_len=8, title=None)]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = spark_session.read.json('hdfs://hdfs:9000/user/ubuntu/corpus-webis-tldr-17.json')\n",
    "df.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5bc46b31-f8af-47c3-9dd0-cdae19c0e613",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 11:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-------+\n",
      "|        subreddit|   word|\n",
      "+-----------------+-------+\n",
      "|        AskReddit|  idiot|\n",
      "|       technology|asshole|\n",
      "|        AskReddit|asshole|\n",
      "|              NAU|dumbass|\n",
      "|        AskReddit|dumbass|\n",
      "|       Torchlight|  idiot|\n",
      "|        AskReddit|dumbass|\n",
      "|       minimalism|  idiot|\n",
      "|        AskReddit|  idiot|\n",
      "|            trees|asshole|\n",
      "|        Minecraft|asshole|\n",
      "|        AskReddit|  idiot|\n",
      "|        AskReddit|asshole|\n",
      "|             halo|   cunt|\n",
      "|            funny|  idiot|\n",
      "|          running|  idiot|\n",
      "|  TalesFromRetail|asshole|\n",
      "|             tifu|dumbass|\n",
      "|        AskReddit|asshole|\n",
      "|explainlikeimfive|asshole|\n",
      "+-----------------+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "\n",
    "############################################################\n",
    "# Process data\n",
    "############################################################\n",
    "\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import StringType\n",
    "import re\n",
    "import json\n",
    "\n",
    "word_array = [\"idiot\", \"dumbass\", \"asshole\", \"cunt\"] \n",
    "process_body_udf = udf(lambda field: re.sub(r'[^a-zA-Z0-9\\s\\nåäöÅÄÖ]', '', field.lower()), StringType())\n",
    "\n",
    "df = df.withColumn(\"content\", process_body_udf(\"content\"))\n",
    "\n",
    "def map_content(row):\n",
    "    subreddit = row[\"subreddit\"]\n",
    "    result = [(subreddit, word) for word in word_array if len(re.findall(r'\\b'+word+r'\\b', row[\"content\"], re.IGNORECASE)) > 0]\n",
    "    return result\n",
    "\n",
    "rdd = df.rdd.flatMap(map_content)\n",
    "\n",
    "rdd.take(10)\n",
    "\n",
    "df_result = rdd.toDF([\"subreddit\", \"word\"])\n",
    "\n",
    "df_result.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a6d09df1-fca9-42d9-89b0-cbbc347adb4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('AskReddit', ('idiot', 1)),\n",
       " ('technology', ('asshole', 1)),\n",
       " ('AskReddit', ('asshole', 1)),\n",
       " ('NAU', ('dumbass', 1)),\n",
       " ('AskReddit', ('dumbass', 1)),\n",
       " ('Torchlight', ('idiot', 1)),\n",
       " ('AskReddit', ('dumbass', 1)),\n",
       " ('minimalism', ('idiot', 1)),\n",
       " ('AskReddit', ('idiot', 1)),\n",
       " ('trees', ('asshole', 1))]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd_map = rdd.map(lambda x: (x[0], (x[1], 1)))\n",
    "rdd_map.take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "06ebafea-3a04-4933-9737-c13ae726fba0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(('AskReddit', 'idiot'), 1),\n",
       " (('technology', 'asshole'), 1),\n",
       " (('AskReddit', 'asshole'), 1),\n",
       " (('NAU', 'dumbass'), 1),\n",
       " (('AskReddit', 'dumbass'), 1),\n",
       " (('Torchlight', 'idiot'), 1),\n",
       " (('AskReddit', 'dumbass'), 1),\n",
       " (('minimalism', 'idiot'), 1),\n",
       " (('AskReddit', 'idiot'), 1),\n",
       " (('trees', 'asshole'), 1)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd_pair = rdd_map.map(lambda x: ((x[0], x[1][0]), x[1][1]))\n",
    "rdd_pair.take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5bb3f16d-17ee-4856-8d69-42c5b79f6987",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(('circlebroke', 'asshole'), 30),\n",
       " (('fantasyfootball', 'asshole'), 28),\n",
       " (('IAmA', 'asshole'), 360),\n",
       " (('steroids', 'asshole'), 13),\n",
       " (('TrueTrueReddit', 'idiot'), 1),\n",
       " (('Braveryjerk', 'asshole'), 6),\n",
       " (('dating_advice', 'asshole'), 204),\n",
       " (('books', 'idiot'), 26),\n",
       " (('religion', 'asshole'), 5),\n",
       " (('RedvsBlue', 'asshole'), 1)]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from operator import add\n",
    "\n",
    "rdd_counts = rdd_pair.reduceByKey(add)\n",
    "rdd_counts.take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "11e0deb8-21b6-48b4-9e2b-be596b51ca54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('circlebroke', 'asshole', 30),\n",
       " ('fantasyfootball', 'asshole', 28),\n",
       " ('IAmA', 'asshole', 360),\n",
       " ('steroids', 'asshole', 13),\n",
       " ('TrueTrueReddit', 'idiot', 1),\n",
       " ('Braveryjerk', 'asshole', 6),\n",
       " ('dating_advice', 'asshole', 204),\n",
       " ('books', 'idiot', 26),\n",
       " ('religion', 'asshole', 5),\n",
       " ('RedvsBlue', 'asshole', 1)]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd_subreddit= rdd_counts.map(lambda x: (x[0][0], x[0][1], x[1]))\n",
    "rdd_subreddit.take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c0a3d28b-0331-4b12-933b-d378ed1bac86",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 72:================================================>    (134 + 13) / 147]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+-------+----+-------+-----+\n",
      "|       subreddit|asshole|cunt|dumbass|idiot|\n",
      "+----------------+-------+----+-------+-----+\n",
      "|      MensRights|     98|  38|     15|   97|\n",
      "|   RSBottingGoal|      0|   0|      0|    1|\n",
      "|      MLBTheShow|      0|   0|      1|    3|\n",
      "|  TrueOffMyChest|     17|   7|      3|   12|\n",
      "|       bookshelf|      0|   1|      0|    0|\n",
      "|       FrozenFun|      1|   0|      0|    0|\n",
      "|    couchsurfing|      0|   0|      0|    1|\n",
      "|          travel|     15|   1|      2|   30|\n",
      "|    marvelheroes|      2|   0|      0|    1|\n",
      "|      QuotesPorn|      3|   0|      0|    3|\n",
      "|        lacrosse|      5|   0|      0|    1|\n",
      "|           HPMOR|      0|   0|      0|    5|\n",
      "|   ThisWarofMine|      0|   0|      0|    1|\n",
      "|     battlefront|      0|   0|      0|    1|\n",
      "|           anime|     40|  11|     13|   54|\n",
      "|freelanceWriters|      0|   0|      0|    2|\n",
      "|    SaltLakeCity|      3|   0|      0|    0|\n",
      "|       metro2033|      0|   0|      0|    1|\n",
      "|DarkSouls2League|      0|   0|      0|    1|\n",
      "|      DnDFetuses|      0|   1|      0|    0|\n",
      "+----------------+-------+----+-------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df = rdd_subreddit.toDF([\"subreddit\", \"word\", \"count\"])\n",
    "\n",
    "pivoted_df = df.groupBy(\"subreddit\").pivot(\"word\").sum(\"count\").na.fill(0)\n",
    "\n",
    "pivoted_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c428e0d2-1175-483a-b50c-efce4eb7fc88",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('Documentaries', 'idiot', 9),\n",
       " ('Documentaries', 'asshole', 7),\n",
       " ('Documentaries', 'cunt', 1),\n",
       " ('Documentaries', 'dumbass', 1),\n",
       " ('freebies', 'idiot', 2),\n",
       " ('restorethefourth', 'idiot', 1),\n",
       " ('BatmanArkham', 'idiot', 3),\n",
       " ('BatmanArkham', 'asshole', 1),\n",
       " ('SanctionedSuicide', 'asshole', 4),\n",
       " ('SanctionedSuicide', 'idiot', 2)]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b8f715fedac16d0",
   "metadata": {
    "collapsed": false,
    "is_executing": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "sc.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f787b7278191241",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
